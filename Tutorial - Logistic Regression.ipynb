{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Using Python\n",
    "\n",
    "This tutorial is for analysts to walk through a simple analysis workflow for social service data. It heavily borrows data and code from [another tutorial](http://blog.yhat.com/posts/logistic-regression-python-rodeo.html).\n",
    "\n",
    "#### Learning Objectives\n",
    "1. Import data\n",
    "2. Explore data\n",
    "3. Descriptive stats\n",
    "4. Logistic regression\n",
    "\n",
    "<br><br>\n",
    "#### Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "from random import randint\n",
    "import math\n",
    "\n",
    "import pylab as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## RESOURCES\n",
    "\n",
    "# http://www.restore.ac.uk/srme/www/fac/soc/wie/research-new/srme/modules/mod4/5/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "#### Read Data from CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>780</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>2.82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>680</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>520</td>\n",
       "      <td>3.74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>780</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>3.78</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>760</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>3.14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>520</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>3.15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>3.45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>3.46</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>2.97</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>2.48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    admit  gre   gpa  rank\n",
       "0       0  380  3.61     3\n",
       "1       1  660  3.67     3\n",
       "2       1  800  4.00     1\n",
       "3       1  640  3.19     4\n",
       "4       0  520  2.93     4\n",
       "5       1  760  3.00     2\n",
       "6       1  560  2.98     1\n",
       "7       0  400  3.08     2\n",
       "8       1  540  3.39     3\n",
       "9       0  700  3.92     2\n",
       "10      0  800  4.00     4\n",
       "11      0  440  3.22     1\n",
       "12      1  760  4.00     1\n",
       "13      0  700  3.08     2\n",
       "14      1  700  4.00     1\n",
       "15      0  480  3.44     3\n",
       "16      0  780  3.87     4\n",
       "17      0  360  2.56     3\n",
       "18      0  800  3.75     2\n",
       "19      1  540  3.81     1\n",
       "20      0  500  3.17     3\n",
       "21      1  660  3.63     2\n",
       "22      0  600  2.82     4\n",
       "23      0  680  3.19     4\n",
       "24      1  760  3.35     2\n",
       "25      1  800  3.66     1\n",
       "26      1  620  3.61     1\n",
       "27      1  520  3.74     4\n",
       "28      1  780  3.22     2\n",
       "29      0  520  3.29     1\n",
       "30      0  540  3.78     4\n",
       "31      0  760  3.35     3\n",
       "32      0  600  3.40     3\n",
       "33      1  800  4.00     3\n",
       "34      0  360  3.14     1\n",
       "35      0  400  3.05     2\n",
       "36      0  580  3.25     1\n",
       "37      0  520  2.90     3\n",
       "38      1  500  3.13     2\n",
       "39      1  520  2.68     3\n",
       "40      0  560  2.42     2\n",
       "41      1  580  3.32     2\n",
       "42      1  600  3.15     2\n",
       "43      0  500  3.31     3\n",
       "44      0  700  2.94     2\n",
       "45      1  460  3.45     3\n",
       "46      1  580  3.46     2\n",
       "47      0  500  2.97     4\n",
       "48      0  440  2.48     4\n",
       "49      0  400  3.35     3"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"http://www.ats.ucla.edu/stat/data/binary.csv\")\n",
    "sample = df.head(50)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "#### Relabel Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = [\"admit\", \"gre\", \"gpa\", \"prestige\"]\n",
    "sample.columns = [\"admit\", \"gre\", \"gpa\", \"prestige\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "#### Quick Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>587.700000</td>\n",
       "      <td>3.389900</td>\n",
       "      <td>2.48500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.516536</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.94446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.395000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre         gpa   prestige\n",
       "count  400.000000  400.000000  400.000000  400.00000\n",
       "mean     0.317500  587.700000    3.389900    2.48500\n",
       "std      0.466087  115.516536    0.380567    0.94446\n",
       "min      0.000000  220.000000    2.260000    1.00000\n",
       "25%      0.000000  520.000000    3.130000    2.00000\n",
       "50%      0.000000  580.000000    3.395000    2.00000\n",
       "75%      1.000000  660.000000    3.670000    3.00000\n",
       "max      1.000000  800.000000    4.000000    4.00000"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit         0.466087\n",
       "gre         115.516536\n",
       "gpa           0.380567\n",
       "prestige      0.944460\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "#### Crosstabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prestige</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>97</td>\n",
       "      <td>93</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prestige   1   2   3   4\n",
       "admit                   \n",
       "0         28  97  93  55\n",
       "1         33  54  28  12"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df['admit'], df['prestige'], rownames=['admit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<br><br>\n",
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0D503FB0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0D5FB1D0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0D6309F0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0D751CD0>]], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd3b2870>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "#### Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummified Prestige\n",
      "   prestige_1  prestige_2  prestige_3  prestige_4\n",
      "0           0           0           1           0\n",
      "1           0           0           1           0\n",
      "2           1           0           0           0\n",
      "3           0           0           0           1\n",
      "4           0           0           0           1\n",
      "Dummified Prestige\n",
      "   admit  gre   gpa  prestige_2  prestige_3  prestige_4\n",
      "0      0  380  3.61           0           1           0\n",
      "1      1  660  3.67           0           1           0\n",
      "2      1  800  4.00           0           0           0\n",
      "3      1  640  3.19           0           0           1\n",
      "4      0  520  2.93           0           0           1\n"
     ]
    }
   ],
   "source": [
    "# dummify rank (aka \"prestige\")\n",
    "dummy_ranks = pd.get_dummies(df['prestige'], prefix='prestige')\n",
    "\n",
    "print(\"Dummified Prestige\")\n",
    "print(dummy_ranks.head())\n",
    "\n",
    "\n",
    "# create a clean data frame for the regression\n",
    "cols_to_keep = [\"admit\", \"gre\", \"gpa\"]\n",
    "\n",
    "# join dummified rank with original data\n",
    "data = df[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_2':])\n",
    "\n",
    "print(\"Dummified Prestige\")\n",
    "print(data.head())\n",
    "#    admit  gre   gpa  prestige_2  prestige_3  prestige_4\n",
    "# 0      0  380  3.61           0           1           0\n",
    "# 1      1  660  3.67           0           1           0\n",
    "# 2      1  800  4.00           0           0           0\n",
    "# 3      1  640  3.19           0           0           1\n",
    "# 4      0  520  2.93           0           0           1\n",
    "\n",
    "# manually add the intercept\n",
    "data['intercept'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "#### Perform Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573147\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "train_cols = data.columns[1:]\n",
    "# Index([gre, gpa, prestige_2, prestige_3, prestige_4], dtype=object)\n",
    "\n",
    "logit = sm.Logit(data['admit'], data[train_cols])\n",
    "\n",
    "# fit the model\n",
    "result = logit.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "#### Regression Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   No. Observations:                  400\n",
      "Model:                          Logit   Df Residuals:                      394\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Tue, 25 Apr 2017   Pseudo R-squ.:                 0.08292\n",
      "Time:                        10:11:46   Log-Likelihood:                -229.26\n",
      "converged:                       True   LL-Null:                       -249.99\n",
      "                                        LLR p-value:                 7.578e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "gre            0.0023      0.001      2.070      0.038         0.000     0.004\n",
      "gpa            0.8040      0.332      2.423      0.015         0.154     1.454\n",
      "prestige_2    -0.6754      0.316     -2.134      0.033        -1.296    -0.055\n",
      "prestige_3    -1.3402      0.345     -3.881      0.000        -2.017    -0.663\n",
      "prestige_4    -1.5515      0.418     -3.713      0.000        -2.370    -0.733\n",
      "intercept     -3.9900      1.140     -3.500      0.000        -6.224    -1.756\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we're very confident that there is an inverse relationship between the probability of being admitted and the prestige of a candidate's undergraduate school.\n",
    "\n",
    "In other words, the probability of being accepted into a graduate program is higher for students who attended a top ranked undergraduate college (`prestige_1==True`) as opposed to a lower ranked school with, say, `prestige_4==True` (remember, a prestige of 1 is the most prestigious and a prestige of 4 is the least prestigious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gre           0.038465\n",
       "gpa           0.015388\n",
       "prestige_2    0.032829\n",
       "prestige_3    0.000104\n",
       "prestige_4    0.000205\n",
       "intercept     0.000465\n",
       "dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get p-values\n",
    "result.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gre</th>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.004409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>0.153684</td>\n",
       "      <td>1.454391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_2</th>\n",
       "      <td>-1.295751</td>\n",
       "      <td>-0.055135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_3</th>\n",
       "      <td>-2.016992</td>\n",
       "      <td>-0.663416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_4</th>\n",
       "      <td>-2.370399</td>\n",
       "      <td>-0.732529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>-6.224242</td>\n",
       "      <td>-1.755716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1\n",
       "gre         0.000120  0.004409\n",
       "gpa         0.153684  1.454391\n",
       "prestige_2 -1.295751 -0.055135\n",
       "prestige_3 -2.016992 -0.663416\n",
       "prestige_4 -2.370399 -0.732529\n",
       "intercept  -6.224242 -1.755716"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get confidence intervals\n",
    "result.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br><br>\n",
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummified Prestige\n",
      "   prestige_1  prestige_2  prestige_3  prestige_4\n",
      "0           0           0           1           0\n",
      "1           0           0           1           0\n",
      "2           1           0           0           0\n",
      "3           0           0           0           1\n",
      "4           0           0           0           1\n",
      "Dummified Prestige\n",
      "   admit  gre   gpa  prestige_2  prestige_3  prestige_4\n",
      "0      0  380  3.61           0           1           0\n",
      "1      1  660  3.67           0           1           0\n",
      "2      1  800  4.00           0           0           0\n",
      "3      1  640  3.19           0           0           1\n",
      "4      0  520  2.93           0           0           1\n",
      "22\n",
      "28.3786\n",
      "(0.52982148608350055, 0.63186538999776665)\n"
     ]
    }
   ],
   "source": [
    "# dummify rank (aka \"prestige\")\n",
    "dummy_ranks = pd.get_dummies(sample['prestige'], prefix='prestige')\n",
    "\n",
    "print(\"Dummified Prestige\")\n",
    "print(dummy_ranks.head())\n",
    "\n",
    "\n",
    "# create a clean data frame for the regression\n",
    "cols_to_keep = [\"admit\", \"gre\", \"gpa\"]\n",
    "\n",
    "# join dummified rank with original data\n",
    "sample = sample[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_2':])\n",
    "\n",
    "print(\"Dummified Prestige\")\n",
    "print(sample.head())\n",
    "#    admit  gre   gpa  prestige_2  prestige_3  prestige_4\n",
    "# 0      0  380  3.61           0           1           0\n",
    "# 1      1  660  3.67           0           1           0\n",
    "# 2      1  800  4.00           0           0           0\n",
    "# 3      1  640  3.19           0           0           1\n",
    "# 4      0  520  2.93           0           0           1\n",
    "\n",
    "# manually add the intercept\n",
    "sample['intercept'] = 1.0\n",
    "\n",
    " # make predictions on the enumerated dataset\n",
    "sample['log_odds'] = result.predict(sample[train_cols])\n",
    "sample[\"odds_ratio\"] = sample[\"log_odds\"].apply(lambda ap: np.exp(ap))\n",
    "sample[\"p\"] = sample[\"odds_ratio\"].apply(lambda odds: odds / (1 + odds))\n",
    "\n",
    "print(sample[\"admit\"].sum())\n",
    "\n",
    "simulations = 10000\n",
    "\n",
    "pr = sample[\"p\"].tolist()\n",
    "# admit_pred = data[\"admit_pred_mod\"].tolist()\n",
    "\n",
    "results = []\n",
    "\n",
    "for sim in range(simulations):\n",
    "    admits = 0\n",
    "    for p in pr:\n",
    "        threshold = int(round(p*100))\n",
    "        draw = randint(0,101)\n",
    "        # print(ap, threshold, draw)\n",
    "        if threshold > draw:\n",
    "            admits += 1\n",
    "#     print(admits)\n",
    "    results.append(admits)\n",
    "\n",
    "print(sum(results)/len(results))\n",
    "            \n",
    "print(\n",
    "    sample[sample[\"admit\"]==1][\"p\"].min(),\n",
    "    sample[sample[\"admit\"]==0][\"p\"].max(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "226.6066\n",
      "(0.52876973418837925, 0.67562156316838085)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2</th>\n",
       "      <th>prestige_3</th>\n",
       "      <th>prestige_4</th>\n",
       "      <th>intercept</th>\n",
       "      <th>log_odds</th>\n",
       "      <th>odds_ratio</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.172627</td>\n",
       "      <td>1.188422</td>\n",
       "      <td>0.543050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.292175</td>\n",
       "      <td>1.339337</td>\n",
       "      <td>0.572529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.738408</td>\n",
       "      <td>2.092602</td>\n",
       "      <td>0.676648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.178385</td>\n",
       "      <td>1.195285</td>\n",
       "      <td>0.544478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.118354</td>\n",
       "      <td>1.125642</td>\n",
       "      <td>0.529554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.369970</td>\n",
       "      <td>1.447691</td>\n",
       "      <td>0.591452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.419246</td>\n",
       "      <td>1.520815</td>\n",
       "      <td>0.603303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217003</td>\n",
       "      <td>1.242348</td>\n",
       "      <td>0.554039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200735</td>\n",
       "      <td>1.222301</td>\n",
       "      <td>0.550016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.517868</td>\n",
       "      <td>1.678446</td>\n",
       "      <td>0.626649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.374314</td>\n",
       "      <td>1.453994</td>\n",
       "      <td>0.592501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>1.492123</td>\n",
       "      <td>0.598736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.720539</td>\n",
       "      <td>2.055540</td>\n",
       "      <td>0.672726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353455</td>\n",
       "      <td>1.423978</td>\n",
       "      <td>0.587455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692380</td>\n",
       "      <td>1.998466</td>\n",
       "      <td>0.666496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.185825</td>\n",
       "      <td>1.204212</td>\n",
       "      <td>0.546323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>780</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.339939</td>\n",
       "      <td>1.404862</td>\n",
       "      <td>0.584176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.078953</td>\n",
       "      <td>1.082154</td>\n",
       "      <td>0.519728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540228</td>\n",
       "      <td>1.716398</td>\n",
       "      <td>0.631865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.573512</td>\n",
       "      <td>1.774488</td>\n",
       "      <td>0.639573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.161221</td>\n",
       "      <td>1.174945</td>\n",
       "      <td>0.540218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.437271</td>\n",
       "      <td>1.548476</td>\n",
       "      <td>0.607609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.128375</td>\n",
       "      <td>1.136980</td>\n",
       "      <td>0.532050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>680</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.192049</td>\n",
       "      <td>1.211729</td>\n",
       "      <td>0.547865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.437594</td>\n",
       "      <td>1.548976</td>\n",
       "      <td>0.607686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.682295</td>\n",
       "      <td>1.978413</td>\n",
       "      <td>0.664251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.578481</td>\n",
       "      <td>1.783327</td>\n",
       "      <td>0.640718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>520</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.204754</td>\n",
       "      <td>1.227223</td>\n",
       "      <td>0.551010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>780</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.423073</td>\n",
       "      <td>1.526646</td>\n",
       "      <td>0.604218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.458299</td>\n",
       "      <td>1.581381</td>\n",
       "      <td>0.612610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217654</td>\n",
       "      <td>1.243157</td>\n",
       "      <td>0.554200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>760</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285836</td>\n",
       "      <td>1.330874</td>\n",
       "      <td>0.570976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224819</td>\n",
       "      <td>1.252096</td>\n",
       "      <td>0.555969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.424948</td>\n",
       "      <td>1.529511</td>\n",
       "      <td>0.604667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.342965</td>\n",
       "      <td>1.409120</td>\n",
       "      <td>0.584911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.212933</td>\n",
       "      <td>1.237301</td>\n",
       "      <td>0.553033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.484133</td>\n",
       "      <td>1.622767</td>\n",
       "      <td>0.618723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.139317</td>\n",
       "      <td>1.149489</td>\n",
       "      <td>0.534773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>3.13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.265696</td>\n",
       "      <td>1.304338</td>\n",
       "      <td>0.566036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>520</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.119428</td>\n",
       "      <td>1.126852</td>\n",
       "      <td>0.529821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.189760</td>\n",
       "      <td>1.208959</td>\n",
       "      <td>0.547298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.335670</td>\n",
       "      <td>1.398877</td>\n",
       "      <td>0.583138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>3.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.315604</td>\n",
       "      <td>1.371087</td>\n",
       "      <td>0.578253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.177029</td>\n",
       "      <td>1.193666</td>\n",
       "      <td>0.544142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328174</td>\n",
       "      <td>1.388431</td>\n",
       "      <td>0.581315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.180255</td>\n",
       "      <td>1.197523</td>\n",
       "      <td>0.544942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.361217</td>\n",
       "      <td>1.435075</td>\n",
       "      <td>0.589335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.116991</td>\n",
       "      <td>1.124109</td>\n",
       "      <td>0.529214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.072354</td>\n",
       "      <td>1.075036</td>\n",
       "      <td>0.518081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.150474</td>\n",
       "      <td>1.162385</td>\n",
       "      <td>0.537548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    admit  gre   gpa  prestige_2  prestige_3  prestige_4  intercept  log_odds  \\\n",
       "0       0  380  3.61           0           1           0        1.0  0.172627   \n",
       "1       1  660  3.67           0           1           0        1.0  0.292175   \n",
       "2       1  800  4.00           0           0           0        1.0  0.738408   \n",
       "3       1  640  3.19           0           0           1        1.0  0.178385   \n",
       "4       0  520  2.93           0           0           1        1.0  0.118354   \n",
       "5       1  760  3.00           1           0           0        1.0  0.369970   \n",
       "6       1  560  2.98           0           0           0        1.0  0.419246   \n",
       "7       0  400  3.08           1           0           0        1.0  0.217003   \n",
       "8       1  540  3.39           0           1           0        1.0  0.200735   \n",
       "9       0  700  3.92           1           0           0        1.0  0.517868   \n",
       "10      0  800  4.00           0           0           1        1.0  0.374314   \n",
       "11      0  440  3.22           0           0           0        1.0  0.400200   \n",
       "12      1  760  4.00           0           0           0        1.0  0.720539   \n",
       "13      0  700  3.08           1           0           0        1.0  0.353455   \n",
       "14      1  700  4.00           0           0           0        1.0  0.692380   \n",
       "15      0  480  3.44           0           1           0        1.0  0.185825   \n",
       "16      0  780  3.87           0           0           1        1.0  0.339939   \n",
       "17      0  360  2.56           0           1           0        1.0  0.078953   \n",
       "18      0  800  3.75           1           0           0        1.0  0.540228   \n",
       "19      1  540  3.81           0           0           0        1.0  0.573512   \n",
       "20      0  500  3.17           0           1           0        1.0  0.161221   \n",
       "21      1  660  3.63           1           0           0        1.0  0.437271   \n",
       "22      0  600  2.82           0           0           1        1.0  0.128375   \n",
       "23      0  680  3.19           0           0           1        1.0  0.192049   \n",
       "24      1  760  3.35           1           0           0        1.0  0.437594   \n",
       "25      1  800  3.66           0           0           0        1.0  0.682295   \n",
       "26      1  620  3.61           0           0           0        1.0  0.578481   \n",
       "27      1  520  3.74           0           0           1        1.0  0.204754   \n",
       "28      1  780  3.22           1           0           0        1.0  0.423073   \n",
       "29      0  520  3.29           0           0           0        1.0  0.458299   \n",
       "30      0  540  3.78           0           0           1        1.0  0.217654   \n",
       "31      0  760  3.35           0           1           0        1.0  0.285836   \n",
       "32      0  600  3.40           0           1           0        1.0  0.224819   \n",
       "33      1  800  4.00           0           1           0        1.0  0.424948   \n",
       "34      0  360  3.14           0           0           0        1.0  0.342965   \n",
       "35      0  400  3.05           1           0           0        1.0  0.212933   \n",
       "36      0  580  3.25           0           0           0        1.0  0.484133   \n",
       "37      0  520  2.90           0           1           0        1.0  0.139317   \n",
       "38      1  500  3.13           1           0           0        1.0  0.265696   \n",
       "39      1  520  2.68           0           1           0        1.0  0.119428   \n",
       "40      0  560  2.42           1           0           0        1.0  0.189760   \n",
       "41      1  580  3.32           1           0           0        1.0  0.335670   \n",
       "42      1  600  3.15           1           0           0        1.0  0.315604   \n",
       "43      0  500  3.31           0           1           0        1.0  0.177029   \n",
       "44      0  700  2.94           1           0           0        1.0  0.328174   \n",
       "45      1  460  3.45           0           1           0        1.0  0.180255   \n",
       "46      1  580  3.46           1           0           0        1.0  0.361217   \n",
       "47      0  500  2.97           0           0           1        1.0  0.116991   \n",
       "48      0  440  2.48           0           0           1        1.0  0.072354   \n",
       "49      0  400  3.35           0           1           0        1.0  0.150474   \n",
       "\n",
       "    odds_ratio         p  \n",
       "0     1.188422  0.543050  \n",
       "1     1.339337  0.572529  \n",
       "2     2.092602  0.676648  \n",
       "3     1.195285  0.544478  \n",
       "4     1.125642  0.529554  \n",
       "5     1.447691  0.591452  \n",
       "6     1.520815  0.603303  \n",
       "7     1.242348  0.554039  \n",
       "8     1.222301  0.550016  \n",
       "9     1.678446  0.626649  \n",
       "10    1.453994  0.592501  \n",
       "11    1.492123  0.598736  \n",
       "12    2.055540  0.672726  \n",
       "13    1.423978  0.587455  \n",
       "14    1.998466  0.666496  \n",
       "15    1.204212  0.546323  \n",
       "16    1.404862  0.584176  \n",
       "17    1.082154  0.519728  \n",
       "18    1.716398  0.631865  \n",
       "19    1.774488  0.639573  \n",
       "20    1.174945  0.540218  \n",
       "21    1.548476  0.607609  \n",
       "22    1.136980  0.532050  \n",
       "23    1.211729  0.547865  \n",
       "24    1.548976  0.607686  \n",
       "25    1.978413  0.664251  \n",
       "26    1.783327  0.640718  \n",
       "27    1.227223  0.551010  \n",
       "28    1.526646  0.604218  \n",
       "29    1.581381  0.612610  \n",
       "30    1.243157  0.554200  \n",
       "31    1.330874  0.570976  \n",
       "32    1.252096  0.555969  \n",
       "33    1.529511  0.604667  \n",
       "34    1.409120  0.584911  \n",
       "35    1.237301  0.553033  \n",
       "36    1.622767  0.618723  \n",
       "37    1.149489  0.534773  \n",
       "38    1.304338  0.566036  \n",
       "39    1.126852  0.529821  \n",
       "40    1.208959  0.547298  \n",
       "41    1.398877  0.583138  \n",
       "42    1.371087  0.578253  \n",
       "43    1.193666  0.544142  \n",
       "44    1.388431  0.581315  \n",
       "45    1.197523  0.544942  \n",
       "46    1.435075  0.589335  \n",
       "47    1.124109  0.529214  \n",
       "48    1.075036  0.518081  \n",
       "49    1.162385  0.537548  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # make predictions on the enumerated dataset\n",
    "data['log_odds'] = result.predict(data[train_cols])\n",
    "data[\"odds_ratio\"] = data[\"log_odds\"].apply(lambda ap: np.exp(ap))\n",
    "data[\"p\"] = data[\"odds_ratio\"].apply(lambda odds: odds / (1 + odds))\n",
    "\n",
    "print(\n",
    "    data[\"admit\"].sum(),\n",
    "    data[\"p\"].sum(),\n",
    ")\n",
    "\n",
    "simulations = 10000\n",
    "\n",
    "pr = data[\"p\"].tolist()\n",
    "# admit_pred = data[\"admit_pred_mod\"].tolist()\n",
    "\n",
    "results = []\n",
    "\n",
    "for sim in range(simulations):\n",
    "    admits = 0\n",
    "    for p in pr:\n",
    "        threshold = int(round(p*100))\n",
    "        draw = randint(0,101)\n",
    "        # print(ap, threshold, draw)\n",
    "        if threshold > draw:\n",
    "            admits += 1\n",
    "#     print(admits)\n",
    "    results.append(admits)\n",
    "\n",
    "print(sum(results)/len(results))\n",
    "            \n",
    "print(\n",
    "    data[data[\"admit\"]==1][\"p\"].min(),\n",
    "    data[data[\"admit\"]==0][\"p\"].max(),\n",
    ")\n",
    "\n",
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127L, 231.30182050201)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    data[\"admit\"].sum(),\n",
    "    data[\"p\"].sum(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3862943611198908, -1.3862943611198908)\n"
     ]
    }
   ],
   "source": [
    "p_success = 0.8\n",
    "p_failure = (1-p_success)\n",
    "odds_success = p_success / p_failure\n",
    "odds_failure = p_failure / p_success\n",
    "log_odds_success = math.log(odds_success)\n",
    "log_odds_failure = math.log(odds_failure)\n",
    "\n",
    "print(log_odds_success, log_odds_failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# SPLIT TRAIN vs TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5870000000000001, 145)\n",
      "(0.5880000000000001, 140)\n",
      "(0.5890000000000001, 138)\n",
      "(0.5900000000000001, 135)\n",
      "(0.5910000000000001, 133)\n",
      "(0.5920000000000001, 127)\n",
      "(0.5930000000000001, 120)\n",
      "(0.5940000000000001, 116)\n",
      "(0.5950000000000001, 113)\n",
      "(0.5960000000000001, 112)\n",
      "(0.5970000000000001, 107)\n",
      "(0.5980000000000001, 106)\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "while threshold < 1.0:\n",
    "    admits = len(data[data[\"p\"]>=threshold])\n",
    "    if admits > 100 and admits < 150:\n",
    "        print(threshold, admits)\n",
    "    threshold += 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127L"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"forecast\"] = data[\"p\"].apply(lambda p: 1 if p >= 0.592 else 0)\n",
    "data[\"forecast\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>log_odds</th>\n",
       "      <th>p</th>\n",
       "      <th>forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.172627</td>\n",
       "      <td>0.543050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.292175</td>\n",
       "      <td>0.572529</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.738408</td>\n",
       "      <td>0.676648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.178385</td>\n",
       "      <td>0.544478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.118354</td>\n",
       "      <td>0.529554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  log_odds         p  forecast\n",
       "0      0  0.172627  0.543050         0\n",
       "1      1  0.292175  0.572529         0\n",
       "2      1  0.738408  0.676648         1\n",
       "3      1  0.178385  0.544478         0\n",
       "4      0  0.118354  0.529554         0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"admit\",\"log_odds\",\"p\",\"forecast\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"test\"] = data[\"admit\"]==data[\"forecast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 120, 0.7)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len(data[data[\"test\"]==True]),\n",
    "    len(data[data[\"test\"]==False]),\n",
    "    len(data[data[\"test\"]==True]) / len(data),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
